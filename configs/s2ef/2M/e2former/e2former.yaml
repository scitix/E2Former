# # Includes base configurations
# includes:
#   - /home/hul/hul/yl2428/SFM_framework_Dec-9/EScAIP/configs/s2ef/2M/base.yml

# trainer: equiformerv2_forces

# model:
#   name: hydra
#   pass_through_head_outputs: True
#   otf_graph: True

#   backbone:
#     model: src.EScAIP.EScAIP_e2former_backbone

#     # Global Configs (EScAIP)
#     activation: gelu
#     direct_force: true
#     hidden_size: 512
#     regress_forces: true
#     use_fp16_backbone: false
#     batch_size: 12  # must match optim.batch_size

#     # Molecular Graph Configs (EScAIP)
#     enforce_max_neighbors_strictly: true
#     distance_function: gaussian
#     max_neighbors: 20
#     max_num_elements: 256   # Adjusted to match atom_type_cnt in code
#     max_num_nodes_per_batch: 150
#     max_radius: 12.0
#     otf_graph: true
#     use_pbc: true
#     use_pbc_single: false

#     # Graph Neural Networks Configs (E2former + EScAIP)
#     atom_embedding_size: 128
#     # Renamed to num_attn_heads to match code
#     num_attn_heads: 8
#     edge_distance_embedding_size: 512
#     edge_distance_expansion_size: 600
#     node_direction_embedding_size: 64
#     node_direction_expansion_size: 10
#     num_layers: 10
#     output_hidden_layer_multiplier: 2
#     readout_hidden_layer_multiplier: 2
#     ffn_hidden_layer_multiplier: 2
#     use_angle_embedding: true

#     # E2former-specific Parameters
#     irreps_node_embedding: "128x0e+64x1e+32x2e"
#     basis_type: gaussian
#     number_of_basis: 128
#     tp_type: v2
#     attn_type: second-order
#     edge_embedtype: default
#     attn_biastype: share
#     ffn_type: default
#     rescale_degree: false
#     nonlinear_message: false
#     norm_layer: layer
#     alpha_drop: 0.1
#     proj_drop: 0.0
#     out_drop: 0.0
#     drop_path_rate: 0.1
#     sparse_attn: false
#     dynamic_sparse_attn_threshold: 1000
#     attn_scalar_head: 1
#     irreps_head: "16x0e"
#     add_rope: false
#     time_embed: false

#   heads:
#     forces:
#       module: src.EScAIP.EScAIP_direct_force_head
#     energy:
#       module: src.EScAIP.EScAIPEnergyHead

# optim:
#   batch_size: 12
#   eval_batch_size: 12
#   load_balancing: atoms
#   num_workers: 9
#   lr_initial: 0.0001
#   optimizer: AdamW
#   optimizer_params:
#     weight_decay: 0.01
#   scheduler: LambdaLR
#   scheduler_params:
#     lambda_type: cosine
#     warmup_factor: 0.2
#     warmup_epochs: 0.1
#     lr_min_factor: 0.5
#   max_epochs: 30
#   clip_grad_norm: 10
#   ema_decay: 0.999
#   eval_every: 30000

# slurm:
#   constraint: "volta32gb"
